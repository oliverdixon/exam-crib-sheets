% Calculus Examination Crib Sheet
% OWD 2023

\input{../preamble.tex}
\newcommand{\modulename}{Calculus}

\DeclareMathOperator{\sgn}{sgn}

\begin{document}

%
% SIDE 1 (OBVERSE)
%

\centering
\begin{tabular}{|m{.31\linewidth}|m{.31\linewidth}|m{.31\linewidth}|}
\hline

\textbf{L'H{\^ o}pital's Rule}:
    If
        $ f $ and $ g $ are differentiable functions at $ x_0 $,
        $ f(x_0) = g(x_0) = 0 $, and
        $ g^\prime(x_0) \neq 0 $,
    then
        $ \lim_{x \to x_0} f(x) / g(x) =
            \lim_{x \to x_0} f^\prime(x) / g^\prime(x) $. &

\textbf{The IVT}:
    Suppose $ a < b $ and $ f $ is continuous on $ [a, b] $. Then, for
    every $ y $ such that
        $ \min(f(a),f(b)) < y < \max(f(a),f(b))$,
    there exist $ x_0 \in (a, b) $ s.t.\ $ f(x_0) = y $. &

\textbf{The Chain Rule}:
    If
        $ g $ is differentiable at $ x $ and
        $ f $ is differentiable at $ g(x) $,
    then
        $ f \circ g $ is differentiable at $ x $, and
        $ (f \circ g)^\prime(x) = f^\prime(g(x)) g^\prime(x) $. \\

\hline

\textbf{The IFT}:
    If
        $ f \colon I \to \mathbb{R} $ is continuous and strictly monotonic,
    then
        $ f^{-1} \colon J \to I$ is also continuous, where
        $ J = f(I) $ and
        $ f^{-1}(f(x)) = x $ and
        $ f(f^{-1}(y)) = y $. &

\textbf{The MVT}:
    If
        $ f \colon [a, b] \to \mathbb{R}$ is continuous and differentiable on
            $ (a, b) $,
    then
        there exist $ x_0 \in (a, b)$ such that
        $ f^\prime(x_0) = \left[ f(b)-f(a) \right] / (b - a) $. &

\textbf{Classifying CPs}:
    If
        $ f \colon [a, b] \to \mathbb{R} $,
        $ f^\prime $, and
        $ f^{\prime\prime} $
        are sensibly defined, and $ x_0 \in (a, b) $ s.t.\ $f^\prime(x_0) = 0$,
    then
        $f^{\prime\prime}(x_0)>0$ means local min., and
        $f^{\prime\prime}(x_0)<0$ means local max. \\

\hline

\textbf{Taylor's Theorem (1)}:
    If
        $ f \in C^{N + 1}(I) $ and
        $ x \in I$,
    then
        $ f(x) =
            \sum_{n = 0}^N \left[
                f^{(n)}(x_0)(x - x_0)^n
            \right] / n! +
            1/N! \int_{x_0}^x
                (x - t)^N f^{(N + 1)}(t)
                \,\mathconst{d}t$. &

\textbf{Taylor's Theorem (2)}:
    The terms under the summation are the \emph{Taylor polynomial} of $ f $ at
    $ x_0 $, of order $ N $. The integral term is known as the \emph{error in
    integral form}. &

\textbf{Taylor's Theorem (3)}:
    The \emph{Lagrange form} of the error is
        $ R_N(x) = \left[
            (x - x_0)^{N + 1} f^{(N + 1)(c)}
        \right] / (N+1)!$,
    for some $ c $ between $ x_0 $ and $ x $. \\

\hline

\textbf{Diff. Eq. (1)}:
    If
        $ u^\prime(x) = cu(x)$, where
        $ c \in \mathbb{R} \setminus \{ 0 \} $ and
        $A$ is an arbitrary constant,
    then
            $ u(x) = A \mathconst{e}^{cx} $. &

\textbf{Diff. Eq. (2)}:
    If
        $ u^{\prime\prime}(x) = -c^2u(x)$,
    then
        $ A \cos(cx) + B \sin(cx) $, where
        $ A $ and $ B $ are arbitrary constants. &

\textbf{Diff. Eq. (3)}:
    If
        $ u^{\prime\prime}(x) = c^2 u(x) $,
    then
        $ u(x) =
            A \mathconst{e}^{cx} + B\mathconst{e}^{-cx} =
            C \cosh(cx) + D\sinh(cx)$,
        for arb.\ constants $ C, D $. \\

\hline

\textbf{Simple Diff. Eqs.}:
    A \emph{simple differential equation} has the form
        $ y^\prime(x) = f(x) $,
    and has solutions
        $ y = \int f(x)
            \, \mathconst{d}x
        + C $,
    for some arbitrary constant $ C $. &

\textbf{Separable Diff. Eqs.}:
    A \emph{separable differential equation} has the form
        $ y^\prime(x) = f(x) / g(y) $.
    It has solutions $ G(y) = F(x) + C$, where
        $ F^\prime = f $ and
        $ G^\prime = g $. &

\textbf{Integrating Factors (1)}:
    A first-order ODE is \emph{linear} if it has the form
        $ a(x)y^\prime(x) + b(x)y + c(x) = 0$.
    In \emph{standard form}, this is
        $ y^\prime(x) + P(x)y + Q(x) = 0 $\ %
    \ldots \\

\hline

\textbf{Integrating Factors (2)}: \ldots\ %
    This can be solved to give
        $ y = -\left[
            \int Q(x) F(x)
            \,\mathconst{d}x
        + C\right] / F(x)$,
    where
        $ F(x) = \exp
            \int P(x)
            \,\mathconst{d}x $
    is the \emph{integrating factor}. &

\textbf{Derivative of Arc Sine}:
    \smash{$
        \dfrac{\mathconst{d}}{\mathconst{d}x} \arcsin(x) =
        \dfrac{1}{\sqrt{1-x^2}}
    $} &

\textbf{Derivative of Arc Cosine}:
    \smash{$
        \dfrac{\mathconst{d}}{\mathconst{d}x} \arccos(x) =
        \dfrac{-1}{\sqrt{1 - x^2}}
    $} \\

\hline

\textbf{Derivative of Arc Tangent}:
    \smash{$
        \dfrac{\mathconst{d}}{\mathconst{d}x} \arctan(x) =
        \dfrac{1}{1+x^2}
    $} &

\textbf{Radian Measure (1)}:
    If
        $ (x, y) \in \mathbb{R}^2 $ with
        $ (x, y) \neq (0, 0) $,
    then
        there is a unique solution to
        $ x = r \cos \theta $ and
        $ y = r \sin \theta$ for
        $ \theta \in (-\pi, \pi] $ and $ r > 0 $. &

\textbf{Radian Measure (2)}:
    If $ x > 0 $, then
        $ \theta = \arctan(y / x)$.
    If $ x = 0 $,
        $ \theta = \sgn(y) \pi / 2$.
    If $ x < 0 $, then
        $ \theta = \arctan(y / x) + \pi $ if $ y \geq 0$,
        or $ \theta = \arctan(y / x) - \pi$ otherwise. \\

\hline

\textbf{Complex Circular Trigonometric Functions}:
    For $ z \in \mathbb{C} $,
        $ \sin(z) = (
            \mathconst{e}^{\mathconst{i}z} -
            \mathconst{e}^{-\mathconst{i}z}
        ) / (2\mathconst{i}) $, and
        $ \cos(z) = (
            \mathconst{e}^{\mathconst{i}z} +
            \mathconst{e}^{-\mathconst{i}z}
        ) / 2 $. Therefore,
        $ \tan(z) = \mathconst{i}(
            \mathconst{e}^{-\mathconst{i}z} -
            \mathconst{e}^{\mathconst{i}z}
        ) / (
            \mathconst{e}^{-\mathconst{i}z} +
            \mathconst{e}^{\mathconst{i}z}
        ) $. &

\textbf{Complex Hyperbolic Trigonometric Functions}:
    For $ z \in \mathbb{C} $,
        $ \sinh(z) = (\mathconst{e}^z - \mathconst{e}^{-z}) / 2$,
        $ \cosh(z) = (\mathconst{e}^z + \mathconst{e}^{-z}) / 2$, and
        $ \tanh(z) = \sinh(z) / \cosh(z)$. &

\textbf{Trigonometric Identities (Hyperbolic Form)}:
    For $ x $ and $ y $,
        $ \sinh(x + y) = \sinh(x) \cosh(y) + \cosh(x) \sinh(y)$, and
        $ \cosh(x + y) = \cosh(x) \cosh(y) + \sinh(x) \sinh(y)$. \\

\hline

\textbf{2nd-Order ODE (MD.1)}:
    Consider $ R(y^{\prime\prime}, y^\prime, x) = 0 $. To solve for $ y(x) $, we
    define a new dependent variable as the derivative of the old dependent
    variable. &

\textbf{\ldots\ (MD.2)}:
    We then solve the resulting first-order ODE, and integrate the solution.
    This works in cases of \emph{missing dependent variables}. &

\textbf{2nd-Order ODE (MI.1)}:
    Consider $ R(y^{\prime\prime}, y^\prime, y) = 0$. To solve this
    \emph{autonomous ODE}, we first define a new independent variable as the old
    dependent variable. \\

\hline

\textbf{\ldots\ (MI.2)}:
    Define a dependent variable as the derivative of the old dependent variable.
    Rewrite the expression in terms of these new variables, and solve. &

\textbf{\ldots\ (MI.3)}:
    Rewrite the solution in terms of the original variables, and solve the
    resulting first-order differential equation. &

\textbf{2nd-Order ODE (HC.1)}:
    Consider a \emph{homogeneous linear ODE} in $ y(x) $ with constant coeffs.
    Take an ansatz of $ \mathconst{e}^{\lambda x} $, substitute this into the
    auxiliary equation, and solve. \\

\hline

\textbf{\ldots\ (HC.2)}:
    If
        $ \lambda \in \mathbb{R} $ is a root of the aux. eq.,
    then
        $ \mathconst{e}^{\lambda x} $ is a solution to the ODE.
    If
        $ \alpha \pm \mathconst{i} \beta \in \mathbb{C} $ are roots,
    then
        $ \mathconst{e}^{\alpha x} \cos \beta x $ and
        $ \mathconst{e}^{\alpha x} \sin \beta x $
        are ODE solutions. &

\textbf{\ldots\ (HC.3)}:
    If $ \lambda $ is an $m$-times repeated root of the aux. eq., with
    $ m \leq n $, then multiplying these solutions by powers of $ x $, up to
    $ x^{m - 1} $, gives more solutions. &

\textbf{\ldots\ (HC.4)}:
    The general solution of the ODE is an arbitrary linear combination of these
    real and complex solutions. \\

\hline

\textbf{2nd-Order ODE (IL.1)}:
    For an \emph{inhomogeneous linear ODE}, first find the general solution of
    the corresponding homogeneous equation. &

\textbf{\ldots\ (IL.2)}:
    Find one solution of the inhomogeneous ODE, and sum it with the solution to
    the homogeneous ODE for the general solution. &

\textbf{2nd-Order ODE (IC.1)}:
    For an \emph{inhomogeneous linear ODE with constant coeffs.}, take an ansatz
    which is of the same type as the RHS, with undetermined coeffs. \\

\hline

\textbf{\ldots\ (IC.2)}:
    If this ansatz ``overlaps'' with the general solution of the homogeneous
    ODE, multiply that part of the guess by $ x $. &

\textbf{\ldots\ (IC.3)}:
    Insert this into the ODE and determine the coeffs. Substitute these values
    into the ansatz, and take the sum of the particular and general solution. &

\textbf{2nd-Order ODE (CP.1)}:
    For a system of coupled ODEs in $ x(t) $ and $ y(t) $, find $ \ddot{x} $ and
    $ \dot{y} $. Use $ \dot{y} $ to eliminate $ \dot{y} $, and use $ \dot{x} $
    to eliminate $ y $ in the ODE. \\

\hline
\end{tabular}
\clearpage

%
% SIDE 2 (REVERSE)
%

\begin{tabular}{|m{.31\linewidth}|m{.31\linewidth}|m{.31\linewidth}|}
\hline

\textbf{\ldots\ (CP.2)}:
    Find the general solution of the resulting ODE for $ x(t) $, and compute
    $ \dot{x}(t) $. Use $ \dot{x} $ to write $ y $ in $ x $ and $ \dot{x} $,
    and compute $ y(t) $ from the general solution of $ x(t) $. &

\textbf{Basic FS}:
    The \emph{Fourier Series} for $f \colon [-\pi, \pi] \to \mathbb{R}$ is
        $ S(x) = a_0/2 + \sum_{n = 1}^\infty
            (a_n \cos nx + b_n \sin nx)$, with
        $ a_n = \int_{-\pi}^\pi
            f(x)\cos nx
            \,\mathconst{d}x / \pi $ and
        $ b_n = \int_{-\pi}^\pi
            f(x)\sin nx
            \,\mathconst{d}x / \pi $. &

\textbf{Tangent Lines to Curves}:
    If
        $ \vec{r}_0 $ is lying on the level curve $ f(x,y) = c $,
    then
        $ \nabla f(\vec{r_0}) \cdot (\vec{r} - \vec{r}_0) $.
    In three variables, this also applies to three-space planes. \\

\hline

\textbf{Periodic Extensions}:
    If
        $ f \colon [-\pi, \pi) \to \mathbb{R} $,
    then its \emph{periodic extension}
        $ \tilde{f} \colon \mathbb{R} \to \mathbb{R}$ is defined by
            $ \tilde{f}(x + 2\pi k) \coloneqq f(x)$ for
            $ k \in \mathbb{Z} $ and
            $ -\pi \leq x < \pi $. &

\textbf{FCT (1)}:
    If
        $ f \colon [-\pi, \pi] \to \mathbb{R} $ is a PWCD${}^\dagger$ function,
        and $ \tilde{f} \colon \mathbb{R} \to \mathbb{R}$ is its $ 2\pi $-PE,
    then
        at $ x \in \mathbb{R} $, the FS of $ f $ converges to
        $ \lim_{N \to \infty}
            S_N(x) = S(x) = [
                \tilde{f}(x^+) + \tilde{f}(x^-)
            ] / 2 $. &

\textbf{FCT (2)}:
    If
        $ \tilde{f} $ is continuous at $ x $,
    then
        $ S(x) = \tilde{f}(x) $.

    [$ {}^\dagger $ \emph{Piecewise continuously differentiable function}] \\

\hline

\textbf{PT}:
    If
        $ f \colon [-\pi, \pi] \to \mathbb{R} $ is a PWCD with Fourier
            coefficients $ a_0 $, $ a_n $, and $ b_n $
            for $ n \in \mathbb{N} $,
    then
        $ \int_{-\pi}^\pi
            f^2(x)
            \,\mathconst{d}x/\pi
        \equiv
            a_0^2 / 2 +
            \sum_{n = 1}^\infty (a_n^2 + b_n^2)$. &

\textbf{Half-Range Series}:
    For $ f \colon [0, \pi] \to \mathbb{R}$,
        $ S_c(x) = a_0 / 2 + \sum_{n = 1}^\infty a_n \cos nx $, and
        $ S_s(x) = \sum_{n = 1}^\infty b_n \sin nx $, where
            $ a_n = 2 \int_0^\pi
                f(x) \cos nx
                \,\mathconst{d}x / \pi$ and
            $ b_n = 2 \int_0^\pi
                f(x) \sin nx
                \,\mathconst{d}x / \pi$. &

\textbf{Complex Exponential Series}:
    For complex-valued coefficients
        $ c_n \in \mathbb{C} $,
        $ S(x) = \sum_{n = -\infty}^\infty
            c_n \mathconst{e}^{\mathconst{i}nx}$,
        where
            $ c_n = \int_{-\pi}^\pi
                f(x) \mathconst{e}^{-\mathconst{i}nx}
                \,\mathconst{d}x / (2 \pi) $
        and $ \overline{c_n} = c_{-n} $ with
            $ n \in \mathbb{N} \cup \{ 0 \} $. \\

\hline

\textbf{FS on Other Intervals (1)}:
    For a function over $ [-L / 2 ,L / 2] $,
        $ S(x) = a_0 / 2 + \sum_{n = 1}^\infty
            [ a_n \cos(2n \pi x / L) +
                b_n \sin(2n \pi x / L)] $,
        where \ldots&

\textbf{FS on Other Intervals (2)}: \ldots\ %
    the cosine coefficients are
        $ a_n = 2 \int_{-L / 2}^{L / 2}
            f(x) \cos(2n \pi x / L)
            \,\mathconst{d}x / L $, and
    the sine coefficients are
        $ b_n = 2 \int_{-L / 2}^{L / 2}
            f(x) \sin(2n \pi x / L)
            \,\mathconst{d}x / L$. &

\textbf{Clairaut's Theorem}:
    If
        $ f(x,y) $ and
        $ f_x $,
        $ f_y $,
        $ f_{xy} $, and
        $ f_{yx} $ are defined throughout an open region containing $ (a, b) $,
        and they are all cont.\ at $ (a, b) $,
    then
        $ f_{xy}(a, b) = f_{yx}(a, b) $. \\

\hline

\textbf{GCL}:
    If
        $ f(x,y) $ is a CDF, and
        $\vec{r}(t) = [x(t), y(t)] $ is a pair of diff.\ functions,
    then
        $ F^\prime(t) =
            x^\prime(t) f_x[x(t), y(t)] +
            y^\prime(t) f_y[x(t), y(t)] $,
        where $ F(t) = f[\vec{r}(t)] $. &

\textbf{Gradient}:
    For some $ f(x,y,z) $,
        $ \nabla f \coloneqq \partial f / \partial x\,\vec{i} +
            \partial f / \partial y\,\vec{j} +
            \partial f / \partial z\,\vec{k} $.
    If
        $ \vec{r}_0 $ is a point,
        and $ \vec{u} $ is a unit vector
    then the DD of $ f $ is
        $ D_{\vec{u}} f(\vec{r}_0) \coloneqq
            \lim_{h \to 0} [f(\vec{r}_0+h\vec{u}) - f(\vec{r}_0)]/h$. &

\textbf{Level Surface}:
    A \emph{level set} of a three-variable function $ F(x,y,z) $ is defined to
    be $ \{ (x,y,z) \in \mathbb{R}^3 \,\vert\,F(x,y,z) = c \} $, for some
    constant $ c \in \mathbb{R} $. \\

\hline

\textbf{Tangent Vector}:
    Let $ \mathcal{S}$ be the level surface of $ F \colon \mathbb{R}^3 \to
    \mathbb{R} $ passing through $ \vec{r}_0 $.
    If
        $ \vec{u} $ is a vector tangent to $ \mathcal{S} $ at
        $ \vec{r}_0 $,
    then
        $ 0 = \vec{u} \cdot \nabla F(\vec{r}_0) $. &


\textbf{Imp. Diff.}:
    If
        $ y(x) $ is defined implicitly by $ f(x,y) = c $
    then
        $ \mathconst{d}y / \mathconst{d}x = -f_x(x,y) / f_y(x,y) $.
    For $F(x,y,z)=c$, then
        $ (\partial z / \partial x)_y = -F_x / F_z $ and
        $ (\partial z / \partial y)_x = -F_y / F_z $. &

\textbf{Laplacian}:
    The \emph{Laplacian} of $f(x,y)$ is
        $ \Delta f \equiv \nabla^2 f =
            \partial^2 f / \partial x^2 + \partial^2 f / \partial y^2 $.
    If
        $ F(r, \theta) = f(r \cos \theta, r \sin \theta) $,
    then
        $ \Delta f \equiv \nabla^2 f =
            \partial^2 F / \partial r^2 + (\partial F/\partial r)/r +
            (\partial^2 F / \partial \theta^2) / r^2$. \\

\hline

\textbf{Types of Regions}:
    \emph{Type-One} Region:
    $ R_1 = \{ (x,y) \in \mathbb{R}^2 \,\vert\,
        a \leq x \leq b,\,
        \varphi_1(x)\leq y\leq\varphi_2(x)
    \}$;
    \emph{Type-Two} Region:
    $ R_2 = \{ (x,y) \in \mathbb{R}^2\,\vert\,
        c \leq y \leq d,\,
        \psi_1(y) \leq x \leq \psi_2(y)
    \}$. &

\textbf{Fubini's Theorem}:
    Let $ f \colon R \to \mathbb{R} $ be cont., with $ R \subset \mathbb{R}^2 $.
    If
        $ R $ is T1,
    then
        $ \iint_R f \,\mathconst{d} A =
            \int_a^b
                \int_{\varphi_1(x)}^{\varphi_2(x)}
                    f(x,y)\,\mathconst{d}y
                \,\mathconst{d}x $.
    If
        $ R $ is T2,
    then
        $ \iint_R f \,\mathconst{d}A =
            \int_c^d
                \int_{\psi_1(y)}^{\psi_2(y)}
                    f(x,y) \,\mathconst{d}x
                \,\mathconst{d}y $. &

\textbf{Centroid}:
    The \emph{centroid} of $ R \subset \mathbb{R}^2 $ is the point
    $ (\overline{x}, \overline{y}) $ such that
    $ \overline{x} = \iint_R x \,\mathconst{d}A / \mathcal{A}(R) $ and
    $ \overline{y} = \iint_R y \,\mathconst{d}A / \mathcal{A}(R)$, where
    $ \mathcal{A}(R) $ is the area of $R$. \\

\hline

\textbf{The Jacobian}:
    \smash{$
        J \coloneqq \det \left(
            \begin{array}{cc}
                \partial x/\partial u &
                \partial x/\partial v \\
                \partial y/\partial u &
                \partial y/\partial v
            \end{array}
        \right)
    $} &

\textbf{Double Integral Transform (1)}:
    If
        $ x(u, v) $ and
        $ y(u, v) $ are CDFs,
        $ f(x, y) $ is cont.,
        $ R \subset \mathbb{R}^2 $, and
        $ \mathcal{S} $ is in the $ (u, v) $-plane that maps one-to-one with
            $ R $,
    then \ldots&

\textbf{Double Integral Transform (2)}: \ldots\ %
    change of variables can be achieved with the double integral result::
    $ \iint_R f(x, y)
        \,\mathconst{d}x \,\mathconst{d}y = $
    $ \iint_\mathcal{S}
        f[ x(u, v), y(u, v) ]\,
        \vert J(u, v) \vert
        \,\mathconst{d}u\,\mathconst{d}v $. \\

\hline

\textbf{Local Extrema}:
    A function $ f \colon \mathbb{R}^2 \to \mathbb{R} $ has a \emph{local
    minimum} at $ (x_0, y_0) $ if $ f(x_0, y_0) \leq f(x, y) $ for all $ (x, y)
    $ in some disc centered at $ ( x_0, y_0 ) $. &

\textbf{Stationary and Saddle Points}:
    If
        $ \nabla f(x_0, y_0) = 0 $,
    then
        $ (x_0, y_0) $ is a \emph{stationary point}.
    If $ (x_0, y_0) $ is a stationary point, but not an extremum, then it is a
    \emph{saddle point}. &

\textbf{Hessian}:
    \smash{$
        \vert H(x, y) \vert \coloneqq \left\vert \left(
            \begin{array}{cc}
                f_{xx}(x, y) & f_{xy}(x, y) \\
                f_{yx}(x, y) & f_{yy}(x, y)
            \end{array}
        \right) \right\vert \eqqcolon \Delta
    $} \\

\hline

\textbf{Classifying Stationary Points (1)}:
    Let $ f(x, y) $ be a cont.\ twice-diff.\ function, and suppose that
    it has a stationary point at $ (x_0, y_0) $ with discriminant $ \Delta =
    \Delta (x_0, y_0) $ &

\textbf{Classifying Stationary Points (2)}:
    If
        $ \Delta > 0 $,
    then
        $ f_{xx}(x_0, y_0) > 0 $: local min. at $ (x_0, y_0) $, and
        $ f_{xx}(x_0, y_0) < 0 $: local max.
    Alternatively, $ \Delta < 0 $ implies a saddle point. &

\textbf{CS Points}:
    A point $ (x_0, y_0) \in \mathcal{C} $ is a \emph{constrained stationary
    point} of $ f $ if
        $ D_{\vec{u}}f(x_0, y_0) =
            \vec{u} \cdot \nabla f(x_0, y_0) =
            0 $
        holds for all vectors $ \vec{u} $ tangent to $ \mathcal{C} $ at
            $ (x_0, y_0) $. \\

\hline

\textbf{Rewriting the Derivative}:
    \smash{$
        \dfrac{\mathconst{d}^2}{\mathconst{d}x^2} =
            \dfrac{\mathconst{d}u}{\mathconst{d}x} = u
            \dfrac{\mathconst{d}u}{\mathconst{d}y}
    $} &

\textbf{Vector Fields (Condition)}:
    If a CD vector field $ \vec{f} = (u, v) $ is a gradient, i.e. $ \vec{f} =
    \nabla\varphi $ for some SF $ \varphi(x, y) $, then its components satisfy
    $ \partial{v}/\partial{x} = \partial{u}/\partial{y} $. &

\textbf{Vector Fields (Identification)}:
    We want to find an SF $ \varphi $ s.t. $ \partial{\varphi}/\partial{x} = u
    $. Integrate up, and subsitute to find a closed form for the constant of
    integration $ g(y) $. \\

\hline

\textbf{Arc Length}:
    If $ \gamma $ is s.t. $ \gamma \colon [a, b] \to \mathbb{R}^2 $, where
    $ \gamma(t) = (x(t), y(t)) $ and $ x, y $ are continuous differentiable,
    $ L(\gamma) =
        \int_a^b \sqrt{x^\prime(t)^2 + y^\prime(t)^2} \mathconst{d}t $. &

\textbf{FTC (1)}:
    If $ f \colon [a, b] \to \mathbb{C} $ is a continuous function, then
    $ \mathconst{d}/\mathconst{d}x
        \left[ \int_a^x f(y) \mathconst{d}y \right] = f(y) $, where
    $ F \colon [a, b] \to \mathbb{R} $ is such that $ F(x) = \int_a^x f $. &

\textbf{FTC (2)}:
    If $ f $ is differentiable on $ [a, b] $ and $ f^\prime $ is continuous on
    $ [a, b] $, then $ \int_a^b f^\prime = f(b) - f(a) $. \\

\hline
\end{tabular}
\end{document}

